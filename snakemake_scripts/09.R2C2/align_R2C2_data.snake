import pandas as pd
from snakemake.utils import validate
#import glob
import os
from itertools import product

##### load config and sample sheets #####
configfile: "R2C2_config.yaml"


TSS_adapter_fwd="AAGCAGTGGTATCAACGCAGAGTAC" 
TSS_adapter_rev="TACTCTGCGTTGATACCACTGCTT"



base_names = ["HTC-Root","HTC-Leaf"]
#base_names = ["HTC-Leaf"]
start_stop = ["TSS", "TES"]

all_possible_adapter = ["TSS", "TES", "TSS_and_TES"]


ranges_of_d = [25,50,100, 150] 
runs = ["R1", "R2"]


rule all:
    input:
        expand("00.data/R2C2_raws/{base_name}_{run_name}_fastqc.zip", base_name = base_names, run_name = runs),
        expand("00.data/ref/{reference}_index", reference = config['reference']),
        expand("02.R2C2_STAR_ALIGNMENTS/{location}_seq_{base_name}_Aligned.sortedByCoord.out.bam",
                location = start_stop, base_name = base_names),
        expand("02.R2C2_STAR_ALIGNMENTS/{location}_seq_{base_name}_Aligned.sortedByCoord.out.bw.plus",
                location = start_stop, base_name = base_names),
        expand("04.generate_bw/{location}_seq_{base_name}.bw", location = start_stop, base_name = base_names),
        expand("05.Generate_matrix_TSS_TES/{base_name}_{location}.gz", 
                location = start_stop, base_name = base_names),
        #expand("06.Annotation_intersection/{base_name}_interesction.bed", base_name = base_names),
        expand("07.Annotation_intersection_filtered/{location}_region_{base_name}_interesction.counts", 
                location = start_stop, base_name = base_names),
        expand("07.Annotation_intersection_filtered/{location}_region_{base_name}_single_bp_intersections.filtered.bed",
                location = start_stop, base_name = base_names),
        expand("07.Annotation_intersection_filtered/{location}_region_{base_name}_single_bp_upstream_intersections.filtered.bed",
                location = start_stop[0], base_name = base_names)
        #expand("08.paraclu/{location}_seq_{base_name}_dval_{d_val}.simplified.bed",
        #        location = start_stop, base_name = base_names, d_val = ranges_of_d)


rule take_metrics_raws:
    input:
        raw_fastq_file= "00.data/R2C2_raws/{base_name}_{run}.fq.gz"
    output:
        "00.data/R2C2_raws/{base_name}_{run}_fastqc.zip"
    message: "Taking Metrics"
    threads: 2 
    shell:"""
    ml FastQC
    fastqc -t {threads} {input}
    """

rule take_all_metrics_raw:
    input:
        all_files = expand("00.data/R2C2_raws/{base_name}_{run_name}_fastqc.zip", 
                base_name = base_names, run_name = runs)
    params: "00.data/R2C2_raws"
    output:
        "00.data/R2C2_raws/multiqc_report.html"
    message: "Gathering All Metrics"
    threads: 2 
    shell:"""
    ml MultiQC

    multiqc {params}
    """



#Since we have sequences where we encounter both the 5' and the 3' adapter on a
#single individual read, we have to do this first as to weed out those reads
#which do in fact have both to enusre

rule trim_reads_of_adapter_TSS_and_TES:
    input:
        raw_fastq_file_r1 = "00.data/R2C2_raws/{base_name}_R1.fq",
        raw_fastq_file_r2 = "00.data/R2C2_raws/{base_name}_R2.fq"
        #raw_fastq_file_r1_output = "01.Adapter_selection/{base_name}_R1_TSS.fq",
        #raw_fastq_file_r2_output = "01.Adapter_selection/{base_name}_R2_TSS.fq"
    params:
        "00.data/R2C2_raws/{base_name}_merged.fq"
    output:
        trimmed_merged_fastq = "01.Adapter_selection/TSS_and_TES_seq_{base_name}_merged.trimmed.fq",
        un_trimmed_merged_fastq = "01.Adapter_selection/TSS_and_TES_seq_{base_name}_merged.untrimmed.fq"
    threads: 10
    message: """Trimming"""
    shell:"""
        TSS_adapter_5_prime="AAGCAGTGGTATCAACGCAGAGTACATGGG"                           
        TES_adapter_3_prime="AAAAAAAAAAAAGTACTCTGCGTTGATACCACTGCTT"

        cat {input.raw_fastq_file_r1} {input.raw_fastq_file_r2} > {params}

        cutadapt -g ${{TSS_adapter_5_prime}}...${{TES_adapter_3_prime}} -m 50 -O 10 -j {threads} --untrimmed-output {output.un_trimmed_merged_fastq} -o {output.trimmed_merged_fastq} {params}
        """


#Take the Reads with only the TSS. Take the rev comp of the 5' adapter and run
#with it 
rule trim_reads_of_adapter_TSS:
    input:
        "01.Adapter_selection/TSS_and_TES_seq_{base_name}_merged.untrimmed.fq"
    params:
        trimmed_merged_5p_fastq = "01.Adapter_selection/TSS_seq_{base_name}_5p_merged.trimmed.fq",
        trimmed_merged_3p_fastq = "01.Adapter_selection/TSS_seq_{base_name}_3p_merged.trimmed.fq",
        trimmed_merged_3p_revcomp_fastq = "01.Adapter_selection/TSS_seq_{base_name}_3p_merged.rev.comp.trimmed.fq"
    output:
        trimmed_merged_fastq = "01.Adapter_selection/TSS_seq_{base_name}_merged.trimmed.fq"
    threads: 10
    message: """Trimming"""
    shell:"""
        TSS_adapter_5_prime="AAGCAGTGGTATCAACGCAGAGTACATGGG"                           
        TSS_adapter_3_prime="CCCATGTACTCTGCGTTGATACCACTGCTT"

        cutadapt -g ${{TSS_adapter_5_prime}} -m 50 -O 10 -j {threads} --discard-untrimmed -o {params.trimmed_merged_5p_fastq} {input}
        cutadapt -a ${{TSS_adapter_3_prime}} -m 50 -O 10 -j {threads} --discard-untrimmed -o {params.trimmed_merged_3p_fastq} {input}

        fastx_reverse_complement -i {params.trimmed_merged_3p_fastq} -o {params.trimmed_merged_3p_revcomp_fastq}

        cat {params.trimmed_merged_3p_revcomp_fastq} {params.trimmed_merged_5p_fastq} > {output.trimmed_merged_fastq}
        """


rule trim_reads_of_adapter_TES:
    input:
        "01.Adapter_selection/TSS_and_TES_seq_{base_name}_merged.untrimmed.fq"
        #raw_fastq_file_r1_output = "01.Adapter_selection/{base_name}_R1_TES.fq",
        #raw_fastq_file_r2_output = "01.Adapter_selection/{base_name}_R2_TES.fq"
    params:
        trimmed_merged_5p_fastq = "01.Adapter_selection/TES_seq_{base_name}_5p_merged.trimmed.fq",
        trimmed_merged_3p_fastq = "01.Adapter_selection/TES_seq_{base_name}_3p_merged.trimmed.fq",
        trimmed_merged_3p_revcomp_fastq = "01.Adapter_selection/TES_seq_{base_name}_3p_merged.rev.comp.trimmed.fq"
    output:
        trimmed_merged_fastq = "01.Adapter_selection/TES_seq_{base_name}_merged.trimmed.fq",
    threads: 10
    message: """Trimming"""
    shell:"""
        TES_adapter_5_prime="AAGCAGTGGTATCAACGCAGAGTACTTTTTTTTTTTT"
        TES_adapter_3_prime="AAAAAAAAAAAAGTACTCTGCGTTGATACCACTGCTT"

        cutadapt -g ${{TES_adapter_5_prime}} -m 50 -O 10 -j {threads} --discard-untrimmed -o {params.trimmed_merged_5p_fastq} {input}
        cutadapt -a ${{TES_adapter_3_prime}} -m 50 -O 10 -j {threads} --discard-untrimmed -o {params.trimmed_merged_3p_fastq} {input}
        
        fastx_reverse_complement -i {params.trimmed_merged_3p_fastq} -o {params.trimmed_merged_3p_revcomp_fastq}
        cat {params.trimmed_merged_3p_revcomp_fastq} {params.trimmed_merged_5p_fastq} > {output.trimmed_merged_fastq}
    	"""


rule generate_star_index:
    input:
        "00.data/ref/{reference}.fa"
    output:
        directory("00.data/ref/{reference}_index")
    threads:
        10
    shell:"""
    mkdir {output}

    STAR --runMode genomeGenerate \
    --genomeDir {output} \
    --genomeFastaFiles {input} \
    --runThreadN {threads} ;
    """

rule align_reads_to_genomes:
    input:
        index_dir=expand("00.data/ref/{reference}_index", reference = config['reference']),
        fq_samp = "01.Adapter_selection/{location}_seq_{base_name}_merged.trimmed.fq"
    threads: 
        10
    params:
        "02.R2C2_STAR_ALIGNMENTS/{location}_seq_{base_name}_"
    output:
        "02.R2C2_STAR_ALIGNMENTS/{location}_seq_{base_name}_Aligned.sortedByCoord.out.bam"
    shell:"""
        STAR --runThreadN {threads} \
        --genomeDir {input.index_dir} \
        --readFilesIn {input.fq_samp} \
        --outSAMmapqUnique 255 \
        --alignIntronMax 10000 \
        --outSAMtype BAM SortedByCoordinate \
        --outFileNamePrefix {params}
    """

rule take_first_tss_basepair:
    input:
        "02.R2C2_STAR_ALIGNMENTS/{location}_seq_{base_name}_Aligned.sortedByCoord.out.bam"
    threads: 1
    output:
        "03.R2C2_FIRST_BP/{location}_seq_{base_name}_first_bp.bed"
    shell: """
    bedtools bamtobed  -i {input} | bioawk -c bed '$strand == "+" {{print \
    $chrom, $start, $start + 1, $name, $score, $strand}} $strand == "-" {{print \
    $chrom, $end -1 , $end , $name, $score, $strand}}' | bedtools sort -i - > {output}
    """

rule generate_geneate_genome_file:
    input:
        "00.data/ref/{reference}.fa"
    output:
        index_file = "00.data/ref/{reference}.fa.fai",
        genome_file = "00.data/ref/{reference}.sizes"
    threads:
        5
    shell:"""
    samtools faidx {input}
    cut -f 1,2 {output.index_file} > {output.genome_file}
    """

#bedtools bedtobam -i {input.reads} -g {input.genome} > {params.bed_to_bam}
rule generate_bw_files_merged:
    input:
        reads = "03.R2C2_FIRST_BP/{location}_seq_{base_name}_first_bp.bed",
        genome = expand("00.data/ref/{reference}.sizes", reference = config['reference'])
    params:
        first_bp_bgh = "03.R2C2_FIRST_BP/{location}_seq_{base_name}_first_bp.bg",
        first_bp_sorted_bgh = "03.R2C2_FIRST_BP/{location}_seq_{base_name}_first_bp.sorted.bg"
    output:
        bigwig = "04.generate_bw/{location}_seq_{base_name}.bw"
    threads:
        5
    shell:"""
    #Calc scaling factor
    reads=$( wc -l {input.reads} | awk '{{print $1}}' | bc -l )
    echo $reads
    mil=1000000
    factor=$(echo "$mil / $reads" | bc -l)
    echo $factor

    bedtools genomecov -i {input.reads} -bga -scale $factor -g {input.genome} > {params.first_bp_bgh}
    sort -k1,1 -k2,2n {params.first_bp_bgh} > {params.first_bp_sorted_bgh}

    bedGraphToBigWig {params.first_bp_sorted_bgh} {input.genome} {output.bigwig}
    """


rule calculate_matrix_TSS:
    input:
       chip_mod = "04.generate_bw/TSS_seq_{base_name}.bw",
       BED = config['annotated_sequences']
    params:
        "{base_name}_TSS"
    threads:
       5
    output:
       "05.Generate_matrix_TSS_TES/{base_name}_TSS.gz"
    shell:"""
        ml deepTools

        computeMatrix reference-point \
        --referencePoint TSS \
        -p {threads} \
        -R {input.BED} \
        -S {input.chip_mod} \
        --samplesLabel {params} \
        -bs 1 \
        -b 500 -a 500 \
        --outFileName {output} \
        --missingDataAsZero
        """


rule calculate_matrix_TES:
    input:
       chip_mod = "04.generate_bw/TES_seq_{base_name}.bw",
       BED = config['annotated_sequences']
    params:
       "{base_name}_TES"
    threads:
       5
    output:
       "05.Generate_matrix_TSS_TES/{base_name}_TES.gz"
    shell:"""
        ml deepTools

        computeMatrix reference-point \
        --referencePoint TES \
        -p {threads} \
        -R {input.BED} \
        -S {input.chip_mod} \
        --samplesLabel {params} \
        -bs 1 \
        -b 500 -a 500 \
        --outFileName {output} \
        --missingDataAsZero
        """

rule generate_BW_files_2:
    input:
        bam_file = "02.R2C2_STAR_ALIGNMENTS/{location}_seq_{base_name}_Aligned.sortedByCoord.out.bam",
        genome_file = expand("00.data/ref/{reference}.sizes", reference = config['reference'])
    output:
        "02.R2C2_STAR_ALIGNMENTS/{location}_seq_{base_name}_Aligned.sortedByCoord.out.bw.plus"
    shell:"""
        ml ucsc

        python3 /work/rjslab/bth29393/jbscripts/file_to_bigwig_pe.py -sort -index -strand {input.genome_file} {input.bam_file}
        """

rule intersect_w_annotation:
    input:
        sequences = config['annotated_sequences_exons'],
        location_stuff = "03.R2C2_FIRST_BP/{location}_seq_{base_name}_first_bp.bed"
    output:
        "06.Annotation_intersection/{location}_region_{base_name}_interesction.bed"
    shell:"""
    bedtools intersect -a {input.sequences} -b {input.location_stuff} -s -c > {output}
    """


rule generate_count_file:
    input:
        "06.Annotation_intersection/{location}_region_{base_name}_interesction.bed"
    output:
        "07.Annotation_intersection_filtered/{location}_region_{base_name}_interesction.counts"
    shell:"""
    python scripts/R2C2_generate_counts.py {input} > {output}
    """

rule generate_split_beds:
    input:
        seq = config['annotated_sequences_exons']
    output:
        "00.data/bed_files/Zm-B73-REFERENCE-NAM-5.0_genes_exon_split.bed"
    shell:"""
    python scripts/single_bp_UTR_exon_split.py {input.seq} > {output}
    """


rule intersect_with_single_bp_features:
    input:
        sequences = "00.data/bed_files/Zm-B73-REFERENCE-NAM-5.0_genes_exon_split.bed",
        location_stuff = "03.R2C2_FIRST_BP/{location}_seq_{base_name}_first_bp.bed"
    output:
        "06.Annotation_intersection/{location}_region_{base_name}_single_bp_intersections.bed"
    shell:"""

    bedtools sort -i {input.sequences} | bedtools intersect -a - -b {input.location_stuff} -s -c > {output}
    """


rule filter_intersect_with_single_bp_features:
    input:
        "06.Annotation_intersection/{location}_region_{base_name}_single_bp_intersections.bed"
    output:
        "07.Annotation_intersection_filtered/{location}_region_{base_name}_single_bp_intersections.filtered.bed"
    shell:"""
    awk '{{ if ($7 > 0) {{ print $0}} }}' {input} > {output}
    """

rule generate_1000_bp_upstream:
    input:
        sequences = config['annotated_sequences_exons']
    params:
        "00.data/bed_files/Zm-B73-REFERENCE-NAM-5.0_transcripts.bed"
    output:
        "06.Annotation_intersection/{location}_region_{base_name}_upstream_intersection.bed"
    shell:"""
    gff2bed < {input} | awk '$4 ~ "transcript:" {{ print $0 }}' > {params}

    python scripts/single_bp_split_bed.py {params} {output}
    """

rule intersect_with_single_bp_features_upstream:
    input:
        sequences =  "06.Annotation_intersection/{location}_region_{base_name}_upstream_intersection.bed",
        location_stuff = "03.R2C2_FIRST_BP/{location}_seq_{base_name}_first_bp.bed"
    output:
        "06.Annotation_intersection/{location}_region_{base_name}_single_bp_upstream_intersections.bed"
    shell:"""

    bedtools sort -i {input.sequences} | bedtools intersect -a - -b {input.location_stuff} -s -c > {output}
    """


rule filter_intersect_with_single_bp_features_upstream:
    input:
        "06.Annotation_intersection/{location}_region_{base_name}_single_bp_upstream_intersections.bed"
    output:
        "07.Annotation_intersection_filtered/{location}_region_{base_name}_single_bp_upstream_intersections.filtered.bed"
    shell:"""
    awk '{{ if ($7 > 0) {{ print $0}} }}' {input} > {output}
    """


#Note that the werid 1 on the end of the awk statment is so that we can 
#Actually use hte group by function to compute the final tally of reads at each
#single bp specific loci
rule pull_single_regions_for_paraclu:
    input:
        fist_bp_bed = "03.R2C2_FIRST_BP/{location}_seq_{base_name}_first_bp.bed"
    params:
       paraclu_all_single_bp = "08.paraclu/{location}_seq_{base_name}.paraclu_format"
    output:
       paraclu_input_file = "08.paraclu/{location}_seq_{base_name}.input"
    shell:"""
    
    awk '{{ OFS="\t"; if($6=="+") print $1,$6,$2,1; else print $1,$6,$3,1}}' {input.fist_bp_bed} > {params.paraclu_all_single_bp}
    
    cat {params.paraclu_all_single_bp} | sort -k1,1 -k2,2 -k3,3n | groupBy -g 1,2,3 -c 4 -o sum > {output}
    """

rule run_paraclu:
    input:
       paraclu_input_file = "08.paraclu/{location}_seq_{base_name}.input"
    output:
       paraclu_output_file = "08.paraclu/{location}_seq_{base_name}_dval_{d_val}.output"
    shell:"""
    ~/software/paraclu-9/paraclu {wildcards.d_val} {input.paraclu_input_file} > {output.paraclu_output_file}
    """

rule process_paraclu:
    input:
       paraclu_output_file = "08.paraclu/{location}_seq_{base_name}_dval_{d_val}.output"
    params:
        cut = "08.paraclu/{location}_seq_{base_name}_dval_{d_val}.cut"
    output:
       paraclu_bed_file = "08.paraclu/{location}_seq_{base_name}_dval_{d_val}.simplified.bed"
    shell:"""
    ~/software/paraclu-9/paraclu-cut.sh {input.paraclu_output_file} > {params.cut}

    awk 'OFS="\t" {{print $1, $3, $4, $1"_"$3"_"$4"_"$2, $6, $2}}' {params.cut} | sort -k1,1V -k2,2n -k6,6 > {output.paraclu_bed_file}
    """


 
